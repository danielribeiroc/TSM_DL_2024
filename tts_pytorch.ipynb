{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0",
      "metadata": {
        "id": "0"
      },
      "outputs": [],
      "source": [
        "# Fast install, might break in the future.\n",
        "!pip install 'safetensors<0.6'\n",
        "!pip install 'sphn<0.2'\n",
        "!pip install --no-deps \"moshi==0.2.11\"\n",
        "# Slow install (will download torch and cuda), but future proof.\n",
        "# !pip install \"moshi==0.2.11\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6",
      "metadata": {
        "id": "6"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "G√©n√©rateur audio TTS avec Kyutai/Moshi TTS\n",
        "Adapt√© pour les conversations psychiatriques structur√©es\n",
        "Installation: pip install 'safetensors<0.6' 'sphn<0.2' --no-deps \"moshi==0.2.11\"\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from scipy.io import wavfile\n",
        "from moshi.models.loaders import CheckpointInfo\n",
        "from moshi.models.tts import DEFAULT_DSM_TTS_REPO, DEFAULT_DSM_TTS_VOICE_REPO, TTSModel\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "GT_FOLDER = \"gt\"\n",
        "OUTPUT_DIR = Path(\"audio_output_kyutai\")\n",
        "\n",
        "# Voix disponibles (voir https://huggingface.co/kyutai/dsm-tts-voices)\n",
        "VOICE_MEDECIN = \"expresso/ex03-ex01_neutral_001_channel1_334s.wav\"\n",
        "VOICE_PATIENT = \"expresso/ex01-ex01_neutral_001_channel1_334s.wav\"\n",
        "\n",
        "# Param√®tres TTS\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "N_Q = 32\n",
        "TEMP = 0.6\n",
        "CFG_COEF = 2.0\n",
        "PADDING_BETWEEN = 1  # secondes de silence entre les tours\n",
        "\n",
        "\n",
        "class KyutaiTTSGenerator:\n",
        "    \"\"\"G√©n√©rateur TTS avec Kyutai Moshi\"\"\"\n",
        "\n",
        "    def __init__(self, device=DEVICE, n_q=N_Q, temp=TEMP):\n",
        "        \"\"\"Initialise le mod√®le TTS (une seule fois)\"\"\"\n",
        "        print(\"üîÑ Chargement du mod√®le Kyutai TTS...\")\n",
        "        print(f\"   Device: {device}\")\n",
        "\n",
        "        checkpoint_info = CheckpointInfo.from_hf_repo(DEFAULT_DSM_TTS_REPO)\n",
        "        self.tts_model = TTSModel.from_checkpoint_info(\n",
        "            checkpoint_info, n_q=n_q, temp=temp, device=device\n",
        "        )\n",
        "\n",
        "        print(\"‚úÖ Mod√®le charg√© avec succ√®s\\n\")\n",
        "        print(f\"Voix disponibles: https://huggingface.co/{DEFAULT_DSM_TTS_VOICE_REPO}\")\n",
        "\n",
        "    def generate_from_json(\n",
        "        self,\n",
        "        json_file: Path,\n",
        "        voice_medecin: str = VOICE_MEDECIN,\n",
        "        voice_patient: str = VOICE_PATIENT,\n",
        "        cfg_coef: float = CFG_COEF,\n",
        "        padding_between: float = PADDING_BETWEEN\n",
        "    ) -> Path:\n",
        "        \"\"\"\n",
        "        G√©n√®re un fichier audio √† partir d'un JSON de conversation\n",
        "\n",
        "        Args:\n",
        "            json_file: Chemin vers le fichier JSON\n",
        "            voice_medecin: Voix pour le m√©decin (speaker_id=0)\n",
        "            voice_patient: Voix pour le patient (speaker_id=1)\n",
        "            cfg_coef: Coefficient CFG pour la g√©n√©ration\n",
        "            padding_between: Secondes de silence entre tours\n",
        "\n",
        "        Returns:\n",
        "            Chemin vers le fichier WAV g√©n√©r√©\n",
        "        \"\"\"\n",
        "        # Charger le JSON\n",
        "        with open(json_file, 'r', encoding='utf-8') as f:\n",
        "            dialogue_data = json.load(f)\n",
        "\n",
        "        print(f\"\\nüéôÔ∏è  G√©n√©ration Kyutai TTS\")\n",
        "        print(f\"    Fichier source : {json_file.name}\")\n",
        "        print(f\"    Conversation : {dialogue_data['metadata']['conversation_id']}\")\n",
        "        print(f\"    M√©decin : {dialogue_data['participants']['medecin']['nom']} ‚Üí {voice_medecin}\")\n",
        "        print(f\"    Patient : {dialogue_data['participants']['patient']['prenom']} {dialogue_data['participants']['patient']['nom']} ‚Üí {voice_patient}\")\n",
        "        print(f\"    Segments : {len(dialogue_data['dialogue'])}\\n\")\n",
        "\n",
        "        # Pr√©parer les textes et voix\n",
        "        texts = []\n",
        "        voices_needed = []\n",
        "\n",
        "        for item in dialogue_data[\"dialogue\"]:\n",
        "            text = item[\"text\"]\n",
        "            speaker_id = item[\"speaker_id\"]\n",
        "\n",
        "            texts.append(text)\n",
        "            # speaker_id = 0 ‚Üí M√©decin, speaker_id = 1 ‚Üí Patient\n",
        "            voice = voice_medecin if speaker_id == 0 else voice_patient\n",
        "            voices_needed.append(voice)\n",
        "\n",
        "        print(f\"üìù Pr√©paration du script ({len(texts)} segments)...\")\n",
        "        entries = self.tts_model.prepare_script(texts, padding_between=padding_between)\n",
        "\n",
        "        print(f\"üé§ Pr√©paration des voix...\")\n",
        "        voice_paths = [self.tts_model.get_voice_path(v) for v in voices_needed]\n",
        "        condition_attributes = self.tts_model.make_condition_attributes(\n",
        "            voice_paths, cfg_coef=cfg_coef\n",
        "        )\n",
        "\n",
        "        print(f\"üîä G√©n√©ration audio...\")\n",
        "        pcms = []\n",
        "\n",
        "        def on_frame(frame):\n",
        "            if (frame != -1).all():\n",
        "                pcm = self.tts_model.mimi.decode(frame[:, 1:, :]).cpu().numpy()\n",
        "                pcms.append(np.clip(pcm[0, 0], -1, 1))\n",
        "            print(f\"  √âtape {len(pcms)}\", end=\"\\r\")\n",
        "\n",
        "        # G√©n√©rer l'audio\n",
        "        with self.tts_model.mimi.streaming(1):\n",
        "            result = self.tts_model.generate(\n",
        "                [entries],\n",
        "                [condition_attributes],\n",
        "                on_frame=on_frame\n",
        "            )\n",
        "\n",
        "        print(\"\\nüîß Assemblage final...\")\n",
        "        audio = np.concatenate(pcms, axis=-1)\n",
        "\n",
        "        # Sauvegarder le fichier WAV\n",
        "        OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "        conv_id = dialogue_data[\"metadata\"][\"conversation_id\"]\n",
        "        output_file = OUTPUT_DIR / f\"audio_{conv_id}.wav\"\n",
        "\n",
        "        sample_rate = self.tts_model.mimi.sample_rate\n",
        "        # Convertir en int16 pour WAV\n",
        "        audio_int16 = (audio * 32767).astype(np.int16)\n",
        "        wavfile.write(output_file, sample_rate, audio_int16)\n",
        "\n",
        "        print(f\"\\n‚úÖ Audio g√©n√©r√© : {output_file}\")\n",
        "        print(f\"‚è±Ô∏è  Dur√©e : {len(audio) / sample_rate:.1f}s\")\n",
        "        print(f\"üîä Sample rate : {sample_rate} Hz\")\n",
        "        print(f\"üíä Diagnostic : {dialogue_data['cas_clinique']['diagnostic_principal']}\")\n",
        "\n",
        "        return output_file\n",
        "\n",
        "\n",
        "def lister_conversations_disponibles(gt_dir: Path) -> list[Path]:\n",
        "    \"\"\"Liste toutes les conversations disponibles\"\"\"\n",
        "    if not gt_dir.exists():\n",
        "        return []\n",
        "    return sorted(gt_dir.glob(\"conv_*.json\"))\n",
        "\n",
        "\n",
        "def afficher_conversations(conv_files: list[Path]):\n",
        "    \"\"\"Affiche la liste des conversations disponibles\"\"\"\n",
        "    print(\"\\nüìö CONVERSATIONS DISPONIBLES\\n\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    for idx, conv_file in enumerate(conv_files, 1):\n",
        "        try:\n",
        "            with open(conv_file, 'r', encoding='utf-8') as f:\n",
        "                data = json.load(f)\n",
        "                metadata = data.get('metadata', {})\n",
        "                participants = data.get('participants', {})\n",
        "                cas = data.get('cas_clinique', {})\n",
        "\n",
        "                conv_id = metadata.get('conversation_id', 'N/A')\n",
        "                medecin = participants.get('medecin', {}).get('nom', 'N/A')\n",
        "                patient_prenom = participants.get('patient', {}).get('prenom', 'N/A')\n",
        "                patient_nom = participants.get('patient', {}).get('nom', 'N/A')\n",
        "                diagnostic = cas.get('diagnostic_principal', 'N/A')\n",
        "                nb_segments = len(data.get('dialogue', []))\n",
        "\n",
        "                print(f\"\\n[{idx}] {conv_file.name}\")\n",
        "                print(f\"    ID: {conv_id}\")\n",
        "                print(f\"    M√©decin: Dr. {medecin}\")\n",
        "                print(f\"    Patient: {patient_prenom} {patient_nom}\")\n",
        "                print(f\"    Diagnostic: {diagnostic[:80]}...\")\n",
        "                print(f\"    Segments: {nb_segments}\")\n",
        "        except Exception as e:\n",
        "            print(f\"\\n[{idx}] {conv_file.name} - ‚ö†Ô∏è Erreur: {e}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "\n",
        "\n",
        "def choisir_conversation(conv_files: list[Path]):\n",
        "    \"\"\"Permet de choisir une conversation\"\"\"\n",
        "    afficher_conversations(conv_files)\n",
        "\n",
        "    while True:\n",
        "        choix = input(f\"\\nChoisissez une conversation (1-{len(conv_files)}) ou 'q' pour quitter : \").strip().lower()\n",
        "\n",
        "        if choix == 'q':\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            idx = int(choix)\n",
        "            if 1 <= idx <= len(conv_files):\n",
        "                return conv_files[idx - 1]\n",
        "            else:\n",
        "                print(f\"‚ùå Choisissez un nombre entre 1 et {len(conv_files)}\")\n",
        "        except ValueError:\n",
        "            print(\"‚ùå Entr√©e invalide\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    print(\"=\" * 80)\n",
        "    print(\"üé¨ G√âN√âRATEUR AUDIO KYUTAI TTS\")\n",
        "    print(\"   Pour conversations psychiatriques structur√©es\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # V√©rifier CUDA\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"‚úÖ CUDA disponible : {torch.cuda.get_device_name(0)}\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  CUDA non disponible, utilisation du CPU (plus lent)\")\n",
        "\n",
        "    # V√©rifier le dossier GT\n",
        "    gt_dir = Path(GT_FOLDER)\n",
        "    if not gt_dir.exists():\n",
        "        print(f\"\\n‚ùå Le dossier '{GT_FOLDER}' n'existe pas!\")\n",
        "        return\n",
        "\n",
        "    # Lister les conversations\n",
        "    conv_files = lister_conversations_disponibles(gt_dir)\n",
        "    if not conv_files:\n",
        "        print(f\"\\n‚ùå Aucune conversation trouv√©e dans '{GT_FOLDER}'\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nüìä {len(conv_files)} conversations trouv√©es\")\n",
        "\n",
        "    # Initialiser le g√©n√©rateur TTS (une seule fois)\n",
        "    try:\n",
        "        generator = KyutaiTTSGenerator()\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Erreur lors du chargement du mod√®le: {e}\")\n",
        "        print(\"\\nüí° Assurez-vous que les d√©pendances sont install√©es:\")\n",
        "        print(\"   pip install 'safetensors<0.6' 'sphn<0.2' --no-deps 'moshi==0.2.11'\")\n",
        "        return\n",
        "\n",
        "    # Boucle de g√©n√©ration\n",
        "    while True:\n",
        "        conv_file = choisir_conversation(conv_files)\n",
        "\n",
        "        if conv_file is None:\n",
        "            print(\"\\nüëã Au revoir!\")\n",
        "            break\n",
        "\n",
        "        try:\n",
        "            output_file = generator.generate_from_json(conv_file)\n",
        "            print(f\"\\nüéâ Succ√®s!\\n\")\n",
        "        except Exception as e:\n",
        "            print(f\"\\n‚ùå Erreur lors de la g√©n√©ration: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "        continuer = input(\"\\nG√©n√©rer une autre conversation? (o/n) : \").strip().lower()\n",
        "        if continuer != 'o':\n",
        "            print(\"\\nüëã Au revoir!\")\n",
        "            break\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}